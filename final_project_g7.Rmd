---
title: "Group 7"
author: "Festus Attah, Manisha Parajuli, Favour Onyido"
date: "2022-11-30"
output: html_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(caret)
```


```{r}
sigmoid <- function(x){
  return(1/(1 + exp(- x)))
}
```

```{r}
set.seed(233)
n <- 1000
p <- 1
rx <- rnorm(n*p, 0, 4)
x <- matrix(rx,ncol=p)
beta <- rpois(p+1,1.56)
y <- as.vector(round(sigmoid(beta%*%t(cbind(1,x))+rnorm(n, 0, 1))))
```

```{r}
#cost function
cost <- function(beta, X, y){
  m <- length(y) #number of rows  of the training data
  h <- sigmoid(X %*% beta)
  J <- (t(-y)%*%log(h)-t(1-y)%*%log(1-h))/m #log likelihood function
  return(J)
}
#gradient function: defines the slope of the LL function
grad <- function(beta, X, y){
  m <- length(y) 
  
  h <- sigmoid(X%*%beta)
  grad <- (t(X)%*%(h - y))/m
  return(grad)
}
Optim_log <- function(x, y) #minimizing the LL function using the optim function
{
  if(!is.matrix(x)){
    x = as.matrix(x)
  }
  m <- dim(x)[1]
  intercept <- rep(1, m)
  x = cbind(intercept, x)
  x_inverse <- solve(t(x)%*%x)
  beta <- x_inverse%*%t(x)%*%y
  costOpti <- optim(beta, fn = cost, gr = grad, X = x, y = y)
  
  return(costOpti$par)
}
```




```{r}
result <- Optim_log(x, y)
result
```



```{r}    
res1 <- glm(y~x,family = "binomial") #validating our function 
summary(res1)
```
## Bootsrap Confidence Interval

```{r}
bootstrap_confi <- function(x, y, b=20, alpha = 0.05){
  n <- dim(x)[1]
  p <- dim(x)[2]
  beta <- matrix(nrow = b, ncol = p+1)
  
  for (i in 1:b) {
    draw <- sample(1:n, n, replace = TRUE)
    boot_x <- x[draw,]
    boot_y <- y[draw]
    beta[i,] <- Optim_log(boot_x, boot_y)
  }
  
  beta_mean <- apply(beta, 2, mean) 
  beta_std_dev <- apply(beta, 2, sd) 
  lower_bound <- beta_mean - qnorm(1 - alpha/2)*beta_std_dev
  upper_bound <- beta_mean + qnorm(1 - alpha/2)*beta_std_dev
  confi_interval <- cbind(beta_mean,lower_bound, upper_bound)
  return(confi_interval)
}
```


```{r}
bootstrap_confi(x, y)
```
## Plotting the Predicted probabilities vrs. the true Data Points
```{r}
intercept <- rep(1, n)
px = cbind(intercept, x)
#data <- data.frame(y,intercept,x)
z <- px%*%result #predicted probabilities 
for (i in 1:dim(x)[2]){
temp <- x[,i]
otemp=temp[order(temp)]
oz=z[order(temp)]
plot(y ~ temp)
lines(sigmoid(oz)~otemp, lwd=2, col="green")  
}
     
```


## Confusion Matrix 

```{r}
conf_mat <- function(x,y, cutoff = 0.5){
  n=dim(x)[1]
  beta <- Optim_log(x,y)
  px <-cbind(rep(1, n),x)
  y_hat <- as.vector(sigmoid(px%*%beta))
  pred <- factor(ifelse(y_hat<cutoff,0,1))
  y <- factor(y)
  levels(y) <- c('Negative', 'Positive')
  levels(pred) <- c('Negative', 'Positive')
  return (confusionMatrix(pred,y))
}
conf_mat(x,y)
```


## Plotting the output from the Confusion Matrix
```{r}


cal_confusion_matrix <- function(mat_tab, cal="acc"){
TN <- mat_tab[1]
FN <- mat_tab[2]
FP <- mat_tab[3]
TP <- mat_tab[4]

#Prevelance pre
pre <- (FN+TP)/(TP+TN+FP+FN)

#Accuracy acc
acc <- (TP+TN)/(TP+TN+FP+FN)

#Sensitivity sen
sen <- TP/(TP+FN)

#Specificity spe
spe <- TN/(TN +FP)

#False discovery ratio fdr
fdr <- FP/(FP+TP)

#Diagnostic odds ratio dor
#getting lr+
fpr <- 1-spe
lrp <- sen/fpr

#getting lr+
fnr <- 1-sen
lrn <- fnr/spe

#getter dor
dor <- lrp/lrn

 switch(cal,
        "pre"= return(paste("Prevelence is", pre)),
        "acc"= return(paste("Accuracy is", acc)),
        "sen"= return(paste("Sensitivity is",sen)),
        "spe"= return(paste("Specificity is",spe)),
        "fdr"= return(paste("False discovery ratio is",fdr)),
        "dor"= return(paste("Diagnostic odds ratio is",dor)))

}
  

```

```{r}
#Calculates results for cutoff between 0.1-0.9

cal2 <- function(x,y,cal){
  cutoff <- seq(0.1, 0.9, 0.1)
  s <- length(cutoff)
  nums <- rep(NA,s)
  for (i in 1:s){
    mat_tab <- conf_mat(x,y,cutoff=cutoff[i])$table
    calculation <- cal_confusion_matrix(mat_tab,cal)
    nums[i] <- as.numeric(tail(strsplit(calculation,split=" ")[[1]],1))
  }
  
  plot(cutoff,nums,xlab="Cutoffs between 0.1-0.9", ylab="Calculated figures")
}

```

```{r}
cal2(x,y,"acc")
```